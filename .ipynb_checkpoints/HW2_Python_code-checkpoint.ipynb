{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4klE3fEouu_3"
   },
   "source": [
    "###HW2 Python part\n",
    "1. Variogram\n",
    "2. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxzET0c8vZ0U"
   },
   "source": [
    "**Part 1. Variogram. Please refer to the HW2 word document for the questions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJZuuufwOhc5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8RP0o4LvnEl"
   },
   "source": [
    "Run the following cell to install the scikit-gstat library, which is needed in this homework. This is necessary to import the \"skgstat library (otherwise you will receive an error)\n",
    "\n",
    "Note that Google CoLab by default restores the environment after the session, so you may need to reinstall it the next time you use Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaNl7QPal6EI"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-gstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1EsXpawwQU9"
   },
   "outputs": [],
   "source": [
    "#import the library, which includes various geostatistics functions\n",
    "import skgstat as skg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX_r4xYoxNq1"
   },
   "source": [
    "Generate and visualize data by running the following two cells\n",
    "\n",
    "**The data is provided to you in this question and you do not need to change the data; just run the following two cells to load and visualize the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fzsj6ON2wd11"
   },
   "outputs": [],
   "source": [
    "#get a sample data from the library\n",
    "#coords: x,y locations of points\n",
    "#vals: value at each point\n",
    "#N here controls the total number of points\n",
    "N = 400\n",
    "coords, vals = skg.data.pancake(N=N).get('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGpKVIpwwt90"
   },
   "outputs": [],
   "source": [
    "#visualize the spatial distribution and values of points\n",
    "plt.scatter(coords[:,0], coords[:,1], c=vals.reshape((N,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRIZoEIbxMVc"
   },
   "source": [
    "Get the variogram plot, recall the three key concepts: nugget, sill, and range\n",
    "\n",
    "Recall that we need bins to calculate variogram\n",
    "\n",
    "The number of bins here is set by \"n_lags\"\n",
    "\n",
    "*It sometimes print two duplicated figures (only need to use one of them if that happens)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYMOVnZJPCMq"
   },
   "outputs": [],
   "source": [
    "#get variogram plot\n",
    "V = skg.Variogram(coords, vals, n_lags=20)\n",
    "#maximum distance to consider\n",
    "V.maxlag = 500\n",
    "\n",
    "V.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvmgGw_42_uL"
   },
   "source": [
    "**Part 2: Clustering**\n",
    "\n",
    "Refer to the four questions in HW2, and follow the instructions to design and create four simple datasets to constrast between different clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfqqCuog37Rf"
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SSlvIEU4v-h"
   },
   "source": [
    "Similar to variogram package, here you will need to install HDBSCAN first by running the following cell before being able to import it as a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI_SYS9U4oaG"
   },
   "outputs": [],
   "source": [
    "%pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXAcs5pc4Mum"
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "#installation guide available in: https://github.com/scikit-learn-contrib/hdbscan\n",
    "\n",
    "#import other clustering packages/functions\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzpzuZdA6zCI"
   },
   "outputs": [],
   "source": [
    "#run this cell to load visualization function\n",
    "def display_data_or_cluster(data, cluster_labels = None):\n",
    "    '''\n",
    "    if you need to visualize data, ignore the second input;\n",
    "    if you need to visualize clusters, feed in both data and cluster_labels\n",
    "    '''\n",
    "    if cluster_labels is None:\n",
    "        plt.scatter(data, np.zeros(data.shape), s=10)#, alpha=0.25\n",
    "    else:\n",
    "        #setting colors\n",
    "        color_palette = sns.color_palette('deep', 20)\n",
    "        cluster_colors = [color_palette[x] if x >= 0\n",
    "                        else (0.75,0.75, 0.75)#(1,1,1)\n",
    "                        for x in cluster_labels]\n",
    "        plt.scatter(data, np.zeros(data.shape), s=10, c=cluster_colors)#, alpha=0.25\n",
    "    \n",
    "    plt.xlim([-10, 103])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oACcp3_M9cKZ"
   },
   "source": [
    "**Dataset creation instructions copied from HW2:** For each dataset, you will place 20 to 30 points (choose yourself) in a one dimensional range [0,100]. For simplicity, you can use an integer value for each point in [0,100] and the 20 points should all have different values. Put the numbers in the array that are marked in the notebook, and run the clustering algorithm on it to get result. You should place the points in a way so that the true clusters are visually apparent. Hint: Draw the data on a paper first to think about what results you might get before putting the numbers into the program, which can help save some efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYq8nJDL5Hub"
   },
   "outputs": [],
   "source": [
    "#create dataset 1, 2, 3 and 4 for the four questions in HW2\n",
    "example = [1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77]\n",
    "\n",
    "#put your point coordinates (1D) in the following arrays (refer to the example above), min coordinate: 1, max: 100\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "data4 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obmhNqFL9EZn"
   },
   "source": [
    "select and display data: you should see your data points appearing as a line (all y values are 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ydjo7Syq6coz"
   },
   "outputs": [],
   "source": [
    "#select which dataset to use, replace \"example\" with the dataset name (e.g., \"data1\") in the parenthesis; the following example uses data1\n",
    "data = np.array(example).reshape(-1,1)\n",
    "display_data_or_cluster(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nyb4bdZQATfa"
   },
   "source": [
    "After specifying dataset using the above cell, run the following cells to get the clustering results of any of the four clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4STMsD-O9tlZ"
   },
   "source": [
    "**k-means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hvo-E2BozHu8"
   },
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters=2).fit(data)\n",
    "display_data_or_cluster(data, clusterer.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6usyWuxD_2lH"
   },
   "source": [
    "**EM (or Gaussian mixture model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpAXvvIw_68T"
   },
   "outputs": [],
   "source": [
    "em = GaussianMixture(n_components=2).fit(data)\n",
    "display_data_or_cluster(data, em.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mh40a3WAt_T"
   },
   "source": [
    "**DBSCAN**: if you see gray-colored points, those are considered as noise points by DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5r-fFde-mrM"
   },
   "outputs": [],
   "source": [
    "clusterer = DBSCAN(eps=9, min_samples=3).fit(data)\n",
    "display_data_or_cluster(data, clusterer.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F989nrPMBTSr"
   },
   "source": [
    "**HDBSCAN**: if you see gray-colored points, those are considered as noise points by HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7Cy8203A31c"
   },
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5).fit(data)\n",
    "display_data_or_cluster(data, clusterer.labels_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_Python_part",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
